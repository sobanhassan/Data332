---
title: "Chapter22And23Answers"
author: "Soban Hassan"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r  results='hide', warning=FALSE, message=FALSE}
# Prerequisites (Packages & Libraries)

lapply(c("tidyverse", "ggrepel", "nycflights13", "ggthemes", "ggplot2", "rlang", "forcats", "gt", "naniar", "gtExtras", "babynames", "janitor", "arrow", "dbplyr", "duckdb", "lubridate", "jsonlite", "repurrrsive"), library, character.only = TRUE)

```

```{r warning=FALSE}
seattle_csv <- open_dataset(
  sources = "seattle-library-checkouts.csv",
  col_types = schema(ISBN = string()),
  format = "csv"
)

## 22.5.3 Exercises

#1. Figure out the most popular book each year.

cleaned_books <- seattle_csv |>
  filter(!is.na(Title) & Title != "<Unknown Title>") |>
  group_by(CheckoutYear, Title) |>
  summarise(TotalCheckouts = sum(Checkouts), .groups = "drop") |>
  arrange(CheckoutYear, desc(TotalCheckouts)) |>
  collect()

most_popular_books <- cleaned_books |>
  group_by(CheckoutYear) |>
  slice_max(order_by = TotalCheckouts, n = 1) |>
  ungroup()

most_popular_books

#2 Which author has the most books in the Seattle library system?

most_books_author <- seattle_csv |>
  filter(!is.na(Creator)) |>
  group_by(Creator) |>
  summarise(BookCount = n_distinct(Title), .groups = "drop") |>
  arrange(desc(BookCount)) |>
  collect() |>         
  slice_head(n = 1)

most_books_author

#3 How has checkouts of books vs ebooks changed over the last 10 years?

format_trends_raw <- seattle_csv |>
  filter(MaterialType %in% c("BOOK", "EBOOK")) |>
  group_by(CheckoutYear, MaterialType) |>
  summarise(TotalCheckouts = sum(Checkouts), .groups = "drop") |>
  collect()

max_year <- max(format_trends_raw$CheckoutYear, na.rm = TRUE)

format_trends <- format_trends_raw |>
  filter(CheckoutYear >= max_year - 9) |>
  arrange(CheckoutYear)

format_trends

## 23.3.5 Exercises

#1. What happens when you use unnest_wider() with unnamed list-columns like df2? What argument is now necessary? What happens to missing values?

# When we use `unnest_wider()` with unnamed list columns, it results in an error because `unnest_wider()` cannot un-nest columns with missing names of the children of the list-column. The error message tells us that the argument `names_sep = "_"` is now necessary, where `"_"` is any separator that we may wish to use. The result names the new columns as `y_1` , `y_2` etc. The missing values are represented with an `NA` .

#2. What happens when you use unnest_longer() with named list-columns like df1? What additional information do you get in the output? How can you suppress that extra detail?

# When we use [`unnest_longer()`] with named list-columns like `df1` , we get a new row for each value of the list, and in addition, we get a new column named `"<name of list column>_id"` which tells us the name of the list child from which the value has been picked up.

# We can suppress this extra detail by adding the argument `indices_include = FALSE` .

#3. From time-to-time you encounter data frames with multiple list-columns with aligned values. For example, in the following data frame, the values of y and z are aligned (i.e. y and z will always have the same length within a row, and the first value of y corresponds to the first value of z). What happens if you apply two unnest_longer() calls to this data frame? How can you preserve the relationship between x and y? (Hint: carefully read the docs).

df4 <- tribble(
  ~x, ~y, ~z,
  "a", list("y-a-1", "y-a-2"), list("z-a-1", "z-a-2"),
  "b", list("y-b-1", "y-b-2", "y-b-3"), list("z-b-1", "z-b-2", "z-b-3")
)

# If we apply two consequtive `unnest_longer()` calls to this data-frame it results in a permutation-combination like situation, where each newly created row of `y` is treated a un-linked to each element of lists in `z` and thus the resulting data-frame produces a combination of all possible values of `y` and `z` .

# Result if we apply two unnest_longer() calls to this data frame
df4 |>
  unnest_longer(y) |>
  unnest_longer(z)

# We can preserve the relationship between `x` and `y` (and `z` ) by including multiple columns in a single call of `unnest_longer()` . The help documentation with `unnest_longer()` provides that

df4 |>
  unnest_longer(c(y, z))

## 23.4.4 Exercises

#1. Roughly estimate when gh_repos was created. Why can you only roughly estimate the date?

#2016-10-25 03:09:53

# Convert the gh_repos into a tibble for easy viewing
ghrepos = tibble(json = gh_repos)
ghrepos |>
  
  # Rectangling the data
  unnest_longer(json) |>
  unnest_wider(json) |>
  
  # Selecting the time variables to find the latest date in the data
  select(created_at, updated_at, pushed_at) |>
  
  # Covert to date-time objects
  mutate(across(.cols = 1:3, .fns = ymd_hms)) |>
  
  # Find the maximum (i.e. the latest) time in the three columns
  summarize(
    max_created_at = max(created_at),
    max_updated_at = max(updated_at),
    max_pushed_at = max(pushed_at)
  ) |>
  
  # Nice display
  gt() |>
  cols_label_with(fn = ~ janitor::make_clean_names(., case = "title")) |>
  gt_theme_538()

#2. The owner column of gh_repo contains a lot of duplicated information because each owner can have many repos. Can you construct an owners data frame that contains one row for each owner? (Hint: does distinct() work with list-cols?)

# Safely extract all 'owner' fields from every repo
owners_df <- map_dfr(gh_repos, function(user_repos) {
  map_dfr(user_repos, function(repo) {
    if (is.list(repo) && "owner" %in% names(repo)) {
      as_tibble(repo$owner)
    } else {
      NULL
    }
  })
}) %>%
  distinct()  # Remove duplicates

print(owners_df)

#3. Follow the steps used for titles to create similar tables for the aliases, allegiances, books, and TV series for the Game of Thrones characters.

# A tibble for aliases
aliases = tibble(json = got_chars) |>
  unnest_wider(json) |>
  select(id, aliases) |>
  unnest_longer(aliases) |>
  filter(aliases != "")
aliases

# A tibble for allegiances
allegiances = tibble(json = got_chars) |>
  unnest_wider(json) |>
  select(id, allegiances) |>
  unnest_longer(allegiances) |>
  filter(allegiances != "")
allegiances

# A tibble for aliases
books = tibble(json = got_chars) |>
  unnest_wider(json) |>
  select(id, books) |>
  unnest_longer(books) |>
  filter(books != "")
books

# A tibble for aliases
tvSeries = tibble(json = got_chars) |>
  unnest_wider(json) |>
  select(id, tvSeries) |>
  unnest_longer(tvSeries) |>
  filter(tvSeries != "")
tvSeries

# We could also try to create a function for this: --

# Create a function to do the same job for each variable in the nested data
got_unnest <- function(variable, nested_tibble){
  
  tibble(json = nested_tibble) |>
  unnest_wider(json) |>
  select(id, variable) |>
  unnest_longer(variable) |>
  filter(variable != "")
}

#4. Explain the following code line-by-line. Why is it interesting? Why does it work for got_chars but might not work in general?

# Convert lsit into tibble for easy viewing and rectangling operations
tibble(json = got_chars) |> 
  
  # Unnest the named column json into 18 different columns
  unnest_wider(json) |> 
  
  # Select to view only the id column, and nested columns which are list-columns
  select(id, where(is.list)) |> 
  
  # Convert into long format by making different row for each column
  pivot_longer(
    where(is.list), 
    names_to = "name", 
    values_to = "value"
  ) |>  
  
  # Now unnest the value column to display one row for each list item
  unnest_longer(value)

#5. In gmaps_cities, what does address_components contain? Why does the length vary between rows? Unnest it appropriately to figure it out. (Hint: types always appears to contain two elements. Does unnest_wider() make it easier to work with than unnest_longer()?) .

# The `address_components` contain the complete words and parts (city, county, state and country) that come for the complete address of the city. The contents are the following: --

# - `long_name` : The actual complete name of the component (city, or county or state or country)

# - `short_name` : The abbreviation for the name (for states and country)

# - `types`: The `address_components` further sub-component `types` contains two elements, one is the type of address, (i..e one of the Locality, Administrative Area Level 2, Administrative Area Level 1, Country) and second is same for all, i.e. type of address `political` .

# The length varies between rows because some address have only **two levels**, for example:\--

# - Washington, United States

# But, others have **three levels** in the address such as: --

# - New York City, New York State, United States

# And, lastly, others have **four levels** in the address such as: --

# - Houston, Harris County, Texas, United States

gmaps_cities |>
  unnest_wider(json) |>
  
  # Remove status as it adds no info
  select(-status) |>
  
  # Unnamed lists, so unnest longer - make rows
  unnest_longer(results) |>
  
  # Named lists to unnest wider into columns
  unnest_wider(results) |>
  
  # Select an id variable and address_components
  select(formatted_address, address_components) |>
  
  # Since we know the address components have City, County, State and Country
  # Names, lets try to create a column for each by unnest_wider
  unnest_wider(address_components, names_sep = "_") |>
  
  # To create tidy data of address levels
  pivot_longer(cols = -formatted_address,
               names_to = "level",
               values_to = "address_components") |>
  mutate(level = parse_number(level)) |>
  
  # Further, making new columns from remaining list-columns
  unnest_wider(address_components) |>
  unnest_wider(types, names_sep = "_") |>
  
  # Remove types_2 ("political) as it does not add any information
  select(-types_2) |>
  
  # Tidying up final display
  rename(level_type = types_1) |>
  relocate(level_type, .before = long_name) |>
  drop_na() |>
  mutate(level_type = snakecase::to_any_case(level_type, "title")) |>
  
  # gt() to display the output nicely
  gt(rowname_col = NULL,
     groupname_col = "formatted_address") |>
  tab_options(row_group.as_column = TRUE) |>
  cols_label_with(fn = ~ janitor::make_clean_names(., case = "title")) |>
  gt_theme_538()

## 23.5.4 Exercises

#1. Rectangle the df_col and df_row below. They represent the two ways of encoding a data frame in JSON.

json_col <- parse_json('
  {
    "x": ["a", "x", "z"],
    "y": [10, null, 3]
  }
')


json_row <- parse_json('
  [
    {"x": "a", "y": 10},
    {"x": "x", "y": null},
    {"x": "z", "y": 3}
  ]
')

df_col <- tibble(json = list(json_col)) 

df_row <- tibble(json = json_row)

# Rectangling df_col
df_col |>
  unnest_wider(json) |>
  unnest_longer(c(x, y))

# Reactangling df_row
df_row |>
  unnest_wider(json)
```

